{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras import layers as L\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/age_gender.csv')\n",
    "\n",
    "## Converting pixels into numpy array\n",
    "data['pixels']=data['pixels'].apply(lambda x:  np.array(x.split(), dtype=\"float32\"))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the images and resize them to 128x128 using OpenCV\n",
    "def resize_image(img, size=(224, 224)):\n",
    "    img = img.reshape((48, 48))  # Reshape to 48x48\n",
    "    img = cv2.resize(img, size)  # Resize to 128x128\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([resize_image(img) for img in data['pixels']])  # Resize each image\n",
    "X = np.expand_dims(X, axis=-1)  # Add the channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to [0, 1]\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total rows: {}'.format(len(data)))\n",
    "print('Total columns: {}'.format(len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "for i in range(1500,1520):\n",
    "    plt.subplot(5,5,(i%25)+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(data['pixels'].iloc[i].reshape(48,48), cmap='gray')\n",
    "    plt.xlabel(\n",
    "        \"Age:\"+str(data['age'].iloc[i])+\n",
    "        \"  Ethnicity:\"+str(data['ethnicity'].iloc[i])+\n",
    "        \"  Gender:\"+ str(data['gender'].iloc[i])\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['age']\n",
    "\n",
    "# Split the data into training and temporary sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=37\n",
    ")  # 70% training, 30% temporary\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=37\n",
    ")  # 50% of 30% = 15% test, 15% validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN Model for Age Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    L.InputLayer(input_shape=(224, 224, 1)),\n",
    "    L.Conv2D(32, (3, 3), activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Conv2D(64, (3, 3), activation='relu'),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Conv2D(128, (3, 3), activation='relu'),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Flatten(),\n",
    "    L.Dense(64, activation='relu'),\n",
    "    L.Dropout(rate=0.5),\n",
    "    L.Dense(1, activation='linear')  # Single output for regression\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Adam optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='huber',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callback for saving the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'age_model.keras',    # Path to save the best model\n",
    "    monitor='val_loss',     # Metric to monitor\n",
    "    save_best_only=True,    # Save only the best model\n",
    "    mode='min',             # Minimize the monitored metric\n",
    "    verbose=1               # Print messages when saving the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with both callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val, y_val),  # Use the separate validation set\n",
    "    batch_size=64,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss: {}'.format(loss))\n",
    "print('Test MAE: {}'.format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and generate predictions\n",
    "def load_model_and_predict(model_path, X_test):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huber Loss function\n",
    "def huber_loss(y_true, y_pred, delta=1.0):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = np.abs(error) <= delta\n",
    "    squared_loss = 0.5 * np.square(error)\n",
    "    linear_loss = delta * (np.abs(error) - 0.5 * delta)\n",
    "    return np.where(is_small_error, squared_loss, linear_loss).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load age model and generate predictions\n",
    "age_model_path = '../models/age_model.keras'\n",
    "age_predictions = load_model_and_predict(age_model_path, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to a 1D array if necessary\n",
    "age_predictions = age_predictions.flatten()\n",
    "y_true_age = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_true_age, age_predictions)\n",
    "mse = mean_squared_error(y_true_age, age_predictions)\n",
    "huber = huber_loss(y_true_age, age_predictions)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Huber Loss: {huber}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_true_age, age_predictions, alpha=0.5)\n",
    "plt.plot([y_true_age.min(), y_true_age.max()], [y_true_age.min(), y_true_age.max()], 'r--', lw=2)\n",
    "plt.xlabel('True Age')\n",
    "plt.ylabel('Predicted Age')\n",
    "plt.title('True vs Predicted Age')\n",
    "\n",
    "# Residual Plot\n",
    "residuals = y_true_age - age_predictions\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(age_predictions, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Age')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "\n",
    "# Histogram of Errors\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Prediction Errors')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
