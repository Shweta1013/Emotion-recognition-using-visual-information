{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras import layers as L\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/age_gender.csv')\n",
    "\n",
    "## Converting pixels into numpy array\n",
    "data['pixels']=data['pixels'].apply(lambda x:  np.array(x.split(), dtype=\"float32\"))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the images and resize them to 128x128 using OpenCV\n",
    "def resize_image(img, size=(224, 224)):\n",
    "    img = img.reshape((48, 48))  # Reshape to 48x48\n",
    "    img = cv2.resize(img, size)  # Resize to 128x128\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([resize_image(img) for img in data['pixels']])  # Resize each image\n",
    "X = np.expand_dims(X, axis=-1)  # Add the channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to [0, 1]\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total rows: {}'.format(len(data)))\n",
    "print('Total columns: {}'.format(len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "for i in range(1500,1520):\n",
    "    plt.subplot(5,5,(i%25)+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(data['pixels'].iloc[i].reshape(48,48), cmap='gray')\n",
    "    plt.xlabel(\n",
    "        \"Age:\"+str(data['age'].iloc[i])+\n",
    "        \"  Ethnicity:\"+str(data['ethnicity'].iloc[i])+\n",
    "        \"  Gender:\"+ str(data['gender'].iloc[i])\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['ethnicity']\n",
    "\n",
    "# Split the data into training and temporary sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=37\n",
    ")  # 70% training, 30% temporary\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=37\n",
    ")  # 50% of 30% = 15% test, 15% validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN Model for Ethnicity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    L.InputLayer(input_shape=(224, 224, 1)),\n",
    "    L.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Conv2D(64, (3, 3), activation='relu'),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Flatten(),\n",
    "    L.Dense(64, activation='relu'),\n",
    "    L.Dropout(rate=0.5),\n",
    "    L.Dense(5)  # Output layer with 5 units for 5 ethnicity classes\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callback for saving the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'ethnicity_model.keras',  # Path to save the best model\n",
    "    monitor='val_accuracy',     # Metric to monitor\n",
    "    save_best_only=True,        # Save only the best model\n",
    "    mode='max',                 # Maximize the monitored metric\n",
    "    verbose=1                   # Print messages when saving the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model with both callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=16,\n",
    "    validation_data=(X_val, y_val),  # Use the separate validation set\n",
    "    batch_size=64,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss: {}'.format(loss))\n",
    "print('Test Accuracy: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load model and generate predictions\n",
    "def load_model_and_predict(model_path, X_test):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title='Confusion Matrix'):\n",
    "    # Convert probabilities to class labels if necessary\n",
    "    if len(y_pred.shape) > 1:\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ethnicity model and generate predictions\n",
    "ethnicity_model_path = '../models/ethnicity_model.keras'\n",
    "ethnicity_model_predictions = load_model_and_predict(ethnicity_model_path, X_test)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "ethnicity_predictions = np.argmax(ethnicity_model_predictions, axis=1)\n",
    "\n",
    "# Define ethnicity class labels\n",
    "ethnicity_labels = np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for ethnicity predictions\n",
    "plot_confusion_matrix(y_test, ethnicity_predictions, labels=ethnicity_labels, title='Ethnicity Prediction Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print accuracy for ethnicity predictions\n",
    "ethnicity_accuracy = accuracy_score(y_test, ethnicity_predictions)\n",
    "print(f\"Ethnicity Prediction Accuracy: {ethnicity_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and print classification report\n",
    "classification_rep = classification_report(y_test, ethnicity_predictions, labels=ethnicity_labels, target_names=[str(label) for label in ethnicity_labels])\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
