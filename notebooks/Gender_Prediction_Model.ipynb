{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras import layers as L\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/age_gender.csv')\n",
    "\n",
    "## Converting pixels into numpy array\n",
    "data['pixels']=data['pixels'].apply(lambda x:  np.array(x.split(), dtype=\"float32\"))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the images and resize them to 128x128 using OpenCV\n",
    "def resize_image(img, size=(224, 224)):\n",
    "    img = img.reshape((48, 48))  # Reshape to 48x48\n",
    "    img = cv2.resize(img, size)  # Resize to 128x128\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([resize_image(img) for img in data['pixels']])  # Resize each image\n",
    "X = np.expand_dims(X, axis=-1)  # Add the channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to [0, 1]\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total rows: {}'.format(len(data)))\n",
    "print('Total columns: {}'.format(len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "for i in range(1500,1520):\n",
    "    plt.subplot(5,5,(i%25)+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(data['pixels'].iloc[i].reshape(48,48), cmap='gray')\n",
    "    plt.xlabel(\n",
    "        \"Age:\"+str(data['age'].iloc[i])+\n",
    "        \"  Ethnicity:\"+str(data['ethnicity'].iloc[i])+\n",
    "        \"  Gender:\"+ str(data['gender'].iloc[i])\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['gender']\n",
    "\n",
    "# Split the data into training and temporary sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=37\n",
    ")  # 70% training, 30% temporary\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=37\n",
    ")  # 50% of 30% = 15% test, 15% validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN Model for Gender Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    L.InputLayer(input_shape=(224, 224, 1)),\n",
    "    L.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Conv2D(64, (3, 3), activation='relu'),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Flatten(),\n",
    "    L.Dense(64, activation='relu'),\n",
    "    L.Dropout(rate=0.5),\n",
    "    L.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the callback for saving the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'gender_model.keras',         # Path to save the model file\n",
    "    monitor='val_loss',           # Metric to monitor\n",
    "    save_best_only=True,          # Save only the best model\n",
    "    mode='min',                   # Minimize the monitored metric\n",
    "    verbose=1                     # Print messages when saving the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with both callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,                # Set the number of epochs\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load model and generate predictions\n",
    "def load_model_and_predict(model_path, X_test):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert numerical prediction to gender label\n",
    "def convert_gender_prediction(prediction):\n",
    "    return 'Male' if prediction == 1 else 'Female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title='Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gender model and generate predictions\n",
    "gender_model_path = '../models/gender_model.keras'\n",
    "gender_model_predictions = load_model_and_predict(gender_model_path, X_test)\n",
    "\n",
    "# Convert model predictions to binary class labels (0 or 1)\n",
    "gender_predictions = (gender_model_predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# Map numeric predictions to human-readable labels\n",
    "gender_labels = ['Female', 'Male']\n",
    "\n",
    "# Convert numeric predictions and true labels to human-readable labels\n",
    "gender_test_labels = [convert_gender_prediction(x) for x in y_test]\n",
    "gender_predictions_labels = [convert_gender_prediction(x) for x in gender_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for gender predictions\n",
    "plot_confusion_matrix(gender_test_labels, gender_predictions_labels, labels=gender_labels, title='Gender Prediction Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print accuracy for gender predictions\n",
    "gender_accuracy = accuracy_score(gender_test_labels, gender_predictions_labels)\n",
    "print(f\"Gender Prediction Accuracy: {gender_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate and print precision, recall, and F1-score\n",
    "precision = precision_score(gender_test_labels, gender_predictions_labels, pos_label='Male')  # Assuming 'Male' is the positive class\n",
    "recall = recall_score(gender_test_labels, gender_predictions_labels, pos_label='Male')\n",
    "f1 = f1_score(gender_test_labels, gender_predictions_labels, pos_label='Male')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(gender_test_labels, gender_predictions_labels, target_names=gender_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
